{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "Updated product ID 66d44ba03472a6465732871b with category 'recycle'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Updated product ID 66d44d2cab31679d1b720c93 with category 'recycle'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Updated product ID 66d44d87182dcae8bfd4f670 with category 'recycle'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Updated product ID 66d452a79f18212201c84e48 with category 'organic'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Updated product ID 66d452c19f18212201c84e49 with category 'recycle'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Updated product ID 66d453d80e4422462f460679 with category 'organic'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Updated product ID 66d454fc0e4422462f46067a with category 'recycle'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Updated product ID 66d4555b0e4422462f46067b with category 'organic'\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "import io\n",
    "\n",
    "# Define the class names (ensure these are in the same order as during training)\n",
    "class_names = ['organic', 'recycle'] \n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'model_small.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client['product_db']\n",
    "collection = db['products']\n",
    "\n",
    "def preprocess_image(img: Image.Image, img_width: int, img_height: int):\n",
    "    \"\"\"Preprocess the image for model prediction.\"\"\"\n",
    "    img = img.resize((img_width, img_height))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "def predict_image(img_array):\n",
    "    \"\"\"Predict the class of the image.\"\"\"\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(prediction)\n",
    "    predicted_class = class_names[predicted_class_index]\n",
    "    return predicted_class\n",
    "\n",
    "def update_product_category(product_id, category):\n",
    "    \"\"\"Update the product category in MongoDB.\"\"\"\n",
    "    collection.update_one({\"_id\": product_id}, {\"$set\": {\"category\": category}})\n",
    "    print(f\"Updated product ID {product_id} with category '{category}'\")\n",
    "\n",
    "def process_and_update_products():\n",
    "    \"\"\"Retrieve products from MongoDB, process images, and update categories.\"\"\"\n",
    "    products = collection.find()\n",
    "    \n",
    "    for product in products:\n",
    "        if 'image' in product:\n",
    "            try:\n",
    "                # Decode the base64 image\n",
    "                img_data = base64.b64decode(product['image'])\n",
    "                img = Image.open(io.BytesIO(img_data))\n",
    "                img = img.convert(\"RGB\")\n",
    "\n",
    "                # Preprocess the image and make a prediction\n",
    "                img_array = preprocess_image(img, img_width=80, img_height=45)  # Ensure these match your model's input size\n",
    "                predicted_class = predict_image(img_array)\n",
    "                \n",
    "                # Update MongoDB with the predicted category\n",
    "                update_product_category(product['_id'], predicted_class)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing product ID {product['_id']}: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_and_update_products()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "import io\n",
    "\n",
    "# Define the class names (ensure these are in the same order as during training)\n",
    "class_names = ['organic', 'recycle']  # Replace with your actual class names\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'model_small.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client['product_db']\n",
    "collection = db['products']\n",
    "\n",
    "def preprocess_image(img: Image.Image, img_width: int, img_height: int):\n",
    "    \"\"\"Preprocess the image for model prediction.\"\"\"\n",
    "    img = img.resize((img_width, img_height))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "def predict_image(img_array):\n",
    "    \"\"\"Predict the class of the image.\"\"\"\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(prediction)\n",
    "    predicted_class = class_names[predicted_class_index]\n",
    "    return predicted_class\n",
    "\n",
    "def update_product_category(product_id, category):\n",
    "    \"\"\"Update the product category in MongoDB.\"\"\"\n",
    "    result = collection.update_one({\"_id\": product_id}, {\"$set\": {\"category\": category}})\n",
    "    if result.modified_count > 0:\n",
    "        print(f\"Product ID {product_id} updated with category '{category}'\")\n",
    "    else:\n",
    "        print(f\"Product ID {product_id} not updated\")\n",
    "\n",
    "def process_and_update_products():\n",
    "    \"\"\"Retrieve products from MongoDB, process images, and update categories.\"\"\"\n",
    "    products = collection.find()\n",
    "    \n",
    "    for product in products:\n",
    "        if 'image' in product:\n",
    "            try:\n",
    "                # Decode the base64 image\n",
    "                img_data = base64.b64decode(product['image'])\n",
    "                img = Image.open(io.BytesIO(img_data))\n",
    "                img = img.convert(\"RGB\")\n",
    "\n",
    "                # Preprocess the image and make a prediction\n",
    "                img_array = preprocess_image(img, img_width=80, img_height=45)  # Ensure these match your model's input size\n",
    "                predicted_class = predict_image(img_array)\n",
    "                \n",
    "                # Update MongoDB with the predicted category\n",
    "                update_product_category(product['_id'], predicted_class)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing product ID {product['_id']}: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_and_update_products()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Product ID 671d1e8187cf34cb41f3aa42 updated with category 'recycle'\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "import io\n",
    "from bson import ObjectId  # To handle MongoDB ObjectId\n",
    "\n",
    "# Define the class names (ensure these are in the same order as during training)\n",
    "class_names = ['organic', 'recycle']  # Replace with your actual class names\n",
    "\n",
    "# Load the trained model\n",
    "model_path = 'model_small.h5'  # Ensure this path is correct relative to your script\n",
    "model = load_model(model_path)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client['ecommerce_db']  # Updated database name\n",
    "collection = db['products']\n",
    "\n",
    "# Image preprocessing parameters (ensure these match your model's input size)\n",
    "IMG_WIDTH = 80\n",
    "IMG_HEIGHT = 45\n",
    "\n",
    "def preprocess_image(img: Image.Image, img_width: int, img_height: int):\n",
    "    \"\"\"\n",
    "    Preprocess the image for model prediction.\n",
    "    \n",
    "    Args:\n",
    "        img (Image.Image): PIL Image.\n",
    "        img_width (int): Width to resize.\n",
    "        img_height (int): Height to resize.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed image array.\n",
    "    \"\"\"\n",
    "    img = img.resize((img_width, img_height))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0  # Normalize to [0,1]\n",
    "    return img_array\n",
    "\n",
    "def predict_image(img_array):\n",
    "    \"\"\"\n",
    "    Predict the class of the image.\n",
    "    \n",
    "    Args:\n",
    "        img_array (np.ndarray): Preprocessed image array.\n",
    "    \n",
    "    Returns:\n",
    "        str: Predicted class name.\n",
    "    \"\"\"\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(prediction)\n",
    "    predicted_class = class_names[predicted_class_index]\n",
    "    return predicted_class\n",
    "\n",
    "def update_product_category(product_id, category):\n",
    "    \"\"\"\n",
    "    Update the product category in MongoDB.\n",
    "    \n",
    "    Args:\n",
    "        product_id (ObjectId): The MongoDB ObjectId of the product.\n",
    "        category (str): The predicted category.\n",
    "    \"\"\"\n",
    "    result = collection.update_one(\n",
    "        {\"_id\": ObjectId(product_id)},\n",
    "        {\"$set\": {\"category\": category}}\n",
    "    )\n",
    "    if result.modified_count > 0:\n",
    "        print(f\"Product ID {product_id} updated with category '{category}'\")\n",
    "    else:\n",
    "        print(f\"Product ID {product_id} not updated or already has category '{category}'\")\n",
    "\n",
    "def process_and_update_products():\n",
    "    \"\"\"\n",
    "    Retrieve products from MongoDB, process images, and update categories.\n",
    "    \"\"\"\n",
    "    # Fetch all products that have an image and category is default or undefined\n",
    "    query = {\n",
    "        \"image\": {\"$exists\": True, \"$ne\": None},\n",
    "        \"category\": {\"$in\": [\"under processing category\"]}  # Adjust based on your default category\n",
    "    }\n",
    "    products = collection.find(query)\n",
    "    \n",
    "    for product in products:\n",
    "        product_id = product['_id']\n",
    "        try:\n",
    "            # Decode the base64 image\n",
    "            img_data = base64.b64decode(product['image'])\n",
    "            img = Image.open(io.BytesIO(img_data))\n",
    "            img = img.convert(\"RGB\")\n",
    "    \n",
    "            # Preprocess the image and make a prediction\n",
    "            img_array = preprocess_image(img, IMG_WIDTH, IMG_HEIGHT)\n",
    "            predicted_class = predict_image(img_array)\n",
    "            \n",
    "            # Update MongoDB with the predicted category\n",
    "            update_product_category(product_id, predicted_class)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product ID {product_id}: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_and_update_products()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
